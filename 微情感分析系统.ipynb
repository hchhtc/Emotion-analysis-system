{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# PaddleHub实战：基于OCEMOTION的中文微情感分析系统"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 一.项目成果展示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<iframe style=\"width:650px;height: 550px;\" src=\"//player.bilibili.com/player.html?aid=974741961&bvid=BV1944y1C7FQ&cid=385189201&page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\"> </iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**视频链接：** [https://www.bilibili.com/video/BV1944y1C7FQ/](https://www.bilibili.com/video/BV1944y1C7FQ/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 二. 项目介绍\n",
    "\n",
    "## 2.1 项目简介：\n",
    "\n",
    "本项目主要基于PaddleHub通过预训练模型Erine-tiny在中文7情感分类数据集OCEMOTION上进行微调从而完成7分类情感分析模型的搭建，并基于PyQt5完成了最终中文微情感分析系统的开发，支持单条和批量文本细粒度情感分类预测，具有前沿性和广泛的应用价值。同时全流程教程讲解将带你玩转一个完整文本分类项目的开发！\n",
    "\n",
    "## 2.2 项目亮点：\n",
    "\n",
    "a.不同于传统的情感2分类（正向和负向），本项目使用了7分类数据集OCEMOTION可以达到更细粒度的情感分析，从而可以更好分析用户评论中表达情感，具有前沿性和广泛的应用价值。\n",
    "\n",
    "b.基于PaddleHub通过预训练模型Erine-tiny的微调完成情感分析模型的搭建。基于大规模未标注语料库的预训练模型（Pretrained Models, PTM) 能够习得通用的语言表示，将预训练模型Fine-tune到下游任务，能够获得比传统分类模型Lstm等更出色的表现，也成为了目前竞赛及项目的主流选择。另外，预训练模型能够避免从零开始训练模型。\n",
    "\n",
    "c.面向小白的全流程实战教程，全流程细致讲解带你拿下一个完整的文本分类实战项目！项目可扩展性高，感兴趣的也可以在其基础上做出更多的优化或迁移到类似的文本分类项目中去哦！喜欢人数多的话后面将考虑推出进阶教程哦！\n",
    "\n",
    "## 2.3 情感分析研究意义：\n",
    "\n",
    "在评论网站、论坛、博客和社交媒体中，可以获得大量表达意见的文本。而这些文本数据都是非结构化的，没有以预先定义的方式组织，数据量庞大通常难以分析、理解和分类，既费时又费钱。而在情感分析系统的帮助下，这种非结构化信息可以依靠自动化业务流程以有效且低成本的方式大规模转换为结构化数据，极大减少人工标注成本，提高效率。情感分析在舆情监控、话题监督、口碑分析等商业分析领域有着非常重要的应用价值。目前该技术也已有着较广泛的应用，例如新浪微博运用情感分析对全网数据进行挖掘构建舆情大数据平台。电商平台运用情感分析来进行商品评论挖掘，作为推荐系统的一部分提高营销效果。小度机器人通过识别用户在聊天中的情绪，帮助选择出更匹配用户情绪的文本进行回复。在不远的未来，情感分析也将成为现代公司不可或缺的工具。但目前情感分析仍然局限于有限的简单分类主要为2分类，而有限的情感分类并不能很好地挖掘文本中包含的微情感，不能很好地满足需求。故细粒度的情感分析研究具有前沿性和更广泛的应用价值。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/30dc5ab4de8d4e7a83f00734b8f6e4e5fc981bc796c54ac9a22755a6631f2363)\n",
    "\n",
    "## 2.4 运行环境要求：\n",
    "\n",
    "注意模型的训练需要到GPU环境，一键fork后选择GPU环境即可运行！\n",
    "\n",
    "可视化界面核心项目代码在work目录下\"中文微情感分析系统\"文件夹内，选择该文件夹并点击下载后将整个文件夹下载到本地，接下来根据文件夹内提供的‘环境配置指南及使用说明’进行操作即可，本地在CPU环境下也可以运行。\n",
    "\n",
    "Github项目地址：[https://github.com/hchhtc123/Emotion-analysis-system](https://github.com/hchhtc123/Emotion-analysis-system)\n",
    "\n",
    "## 2.5 项目总技术路线\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/0e9b9c76005d4493a2a6536cdce5093fe138b6a02c01439eb57284cd4a98591f)\n",
    "\n",
    "a.对中文情感7分类数据集OCEMOTION进行数据清洗，并按照具体类别按8:1:1的比例划分训练、验证和测试数据集。\n",
    "\n",
    "b.基于PaddleHub通过预训练模型的微调完成7分类中文微情感分析模型的训练与优化。\n",
    "\n",
    "c.基于PyQt5完成可视化界面的开发，支持单条和批量文本情感分类预测。最后通过pyinstaller完成系统的打包便于演示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 三. OCEMOTION数据集\n",
    "\n",
    "OCEMOTION是包含7个分类的细粒度情感性分析数据集，其中7个情感类别分别为sadness、happiness、disgust、anger、like、surprise、fear，适用于构建细粒度情感分析模型。  文件格式为：id 句子 标签，以'\\t'分隔。\n",
    "\n",
    "数据集引用说明：\n",
    "\n",
    "Minglei Li, Yunfei Long, Qin Lu, and Wenjie Li. “Emotion Corpus Construction Based on Selection from Hashtags.” In Proceedings of International Conference on Language Resources and Evaluation (LREC). Portorož, Slovenia, 2016\n",
    "\n",
    "论文链接: https://www.aclweb.org/anthology/L16-1291.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "      OCEMOTION数据集已上传AI Studio，在数据集那搜索“OCEMOTION-中文7分类细粒度情感分析数据集”后添加即可。\n",
    "      \n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/dcaa27856f9548d09a9bac1d3a9dc49bcb1cf8fd7937401ea834990aac2a4795)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "    该OCEMOTION数据集具体下载主要来自于作者入门NLP时参加的全球人工智能技术创新大赛【热身赛二】提供的训练数据，比赛地址：https://tianchi.aliyun.com/competition/entrance/531865/information 感兴趣的也可以去了解下那个比赛,是道很经典的多任务赛题哦，适合学习！\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/23bc4a41c8324259a65c3d7cc231e89778e9c476ea5444d9a3d86d53e2e3f793)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "> 扩展:分享下个人收藏的一些很不错的数据集查找网站：\n",
    "\n",
    ">Graviti Open Datasets：[https://gas.graviti.cn/open-datasets](https://gas.graviti.cn/open-datasets)\n",
    "\n",
    ">天池数据集：[https://tianchi.aliyun.com/dataset](https://tianchi.aliyun.com/dataset)\n",
    "\n",
    ">Papers With Code数据集：[https://www.paperswithcode.com/datasets](https://www.paperswithcode.com/datasets)\n",
    "\n",
    ">AI Studio数据集：[https://aistudio.baidu.com/aistudio/datasetoverview](https://aistudio.baidu.com/aistudio/datasetoverview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.1 解压并查看数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/data/data100731\n",
      "Archive:  shuju.zip\n",
      "  inflating: OCEMOTION.csv           \n"
     ]
    }
   ],
   "source": [
    "# 解压数据集\r\n",
    "%cd /home/aistudio/data/data100731/\r\n",
    "!unzip shuju.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 使用pandas读取数据集\r\n",
    "import pandas as pd\r\n",
    "data = pd.read_csv('OCEMOTION.csv', sep='\\t',header=None)\r\n",
    "# 由于该数据集没有列名，故需要为其添加上列名以便于更好处理\r\n",
    "data.columns = [\"id\", \"text_a\", \"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text_a</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>'你知道多伦多附近有什么吗?哈哈有破布耶...真的书上写的你听哦...你家那块破布是世界上最...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>平安夜,圣诞节,都过了,我很难过,和妈妈吵了两天,以死相逼才终止战争,现在还处于冷战中。</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>我只是自私了一点,做自己想做的事情!</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>让感动的不仅仅是雨过天晴,还有泪水流下来的迷人眼神。</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>好日子</td>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             text_a      label\n",
       "0   0  '你知道多伦多附近有什么吗?哈哈有破布耶...真的书上写的你听哦...你家那块破布是世界上最...    sadness\n",
       "1   1       平安夜,圣诞节,都过了,我很难过,和妈妈吵了两天,以死相逼才终止战争,现在还处于冷战中。    sadness\n",
       "2   2                                 我只是自私了一点,做自己想做的事情!    sadness\n",
       "3   3                         让感动的不仅仅是雨过天晴,还有泪水流下来的迷人眼神。  happiness\n",
       "4   4                                                好日子  happiness"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看数据前5条内容\r\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35315 entries, 0 to 35314\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      35315 non-null  int64 \n",
      " 1   text_a  35315 non-null  object\n",
      " 2   label   35315 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 827.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# 查看数据文件信息，可以看出总共有35315条数据\r\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    35315.000000\n",
       "mean        48.214328\n",
       "std         84.391942\n",
       "min          3.000000\n",
       "25%         18.000000\n",
       "50%         34.000000\n",
       "75%         67.000000\n",
       "max      12326.000000\n",
       "Name: text_a, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计评论文本长度信息,从平均长度可以看出属于短文本\r\n",
    "data['text_a'].map(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sadness      12475\n",
       "happiness     8894\n",
       "disgust       4347\n",
       "anger         4068\n",
       "like          4042\n",
       "surprise       899\n",
       "fear           590\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计数据集中7种情感类别标签的分布情况\r\n",
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 可视化标签分布情况\r\n",
    "%matplotlib inline\r\n",
    "data['label'].value_counts(normalize=True).plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.2 数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 导入所需包\r\n",
    "import re\r\n",
    "import os\r\n",
    "import shutil\r\n",
    "from tqdm import tqdm\r\n",
    "from collections import defaultdict\r\n",
    "\r\n",
    "# 定义数据清洗函数:\r\n",
    "\r\n",
    "# 清洗分隔字符\r\n",
    "def clean_duplication(text):\r\n",
    "    left_square_brackets_pat = re.compile(r'\\[+')\r\n",
    "    right_square_brackets_pat = re.compile(r'\\]+')\r\n",
    "    punct = [',', '\\\\.', '\\\\!', '，', '。', '！', '、', '\\?', '？']\r\n",
    "\r\n",
    "    def replace(string, char):\r\n",
    "        pattern = char + '{2,}'\r\n",
    "        if char.startswith('\\\\'):\r\n",
    "            char = char[1:]\r\n",
    "        string = re.sub(pattern, char, string)\r\n",
    "        return string\r\n",
    "\r\n",
    "    text = left_square_brackets_pat.sub('', text)\r\n",
    "    text = right_square_brackets_pat.sub('', text)\r\n",
    "    for p in punct:\r\n",
    "        text = replace(text, p)\r\n",
    "    return text\r\n",
    "\r\n",
    "def emoji2zh(text, inverse_emoji_dict):\r\n",
    "    for emoji, ch in inverse_emoji_dict.items():\r\n",
    "        text = text.replace(emoji, ch)\r\n",
    "    return text\r\n",
    "\r\n",
    "# 清洗数据集中特殊表情，通过json文件的映射用中文替代表情\r\n",
    "def clean_emotion(data_path, emoji2zh_data, save_dir, train=True):\r\n",
    "    data = defaultdict(list)\r\n",
    "    filename = os.path.basename(data_path)\r\n",
    "    with open(data_path, 'r', encoding='utf8') as f:\r\n",
    "        texts = f.readlines()\r\n",
    "        for line in tqdm(texts, desc=data_path):\r\n",
    "            if train:\r\n",
    "                id_, text, label = line.strip().split('\\t')\r\n",
    "            else:\r\n",
    "                id_, text = line.strip().split('\\t')\r\n",
    "            data['id'].append(id_)\r\n",
    "            text = emoji2zh(text, emoji2zh_data)\r\n",
    "            text = clean_duplication(text)\r\n",
    "            data['text_a'].append(text)\r\n",
    "            if train:\r\n",
    "                data['label'].append(label)\r\n",
    "    df = pd.DataFrame(data)\r\n",
    "    if not os.path.exists(save_dir):\r\n",
    "        os.makedirs(save_dir)\r\n",
    "    df.to_csv(os.path.join(save_dir, filename), index=False,\r\n",
    "              encoding='utf8', header=False, sep='\\t')\r\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 读取表情映射json文件（放在work目录下，文件名为emoji2zh.json），用于替换表情为中文字符\r\n",
    "import json\r\n",
    "emoji2zh_data = json.load(open('/home/aistudio/work/emoji2zh.json', 'r', encoding='utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aistudio/data/data100731/OCEMOTION.csv: 100%|██████████| 35694/35694 [00:04<00:00, 7890.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# 对数据进行数据清洗\r\n",
    "data = clean_emotion('/home/aistudio/data/data100731/OCEMOTION.csv',emoji2zh_data,'./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 去掉无用的id列，保存其格式为text_a,label\r\n",
    "data = data[['text_a', 'label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.3 转换情感类别标签\n",
    "\n",
    "由于类别名为英文，此处主要将英文类别名转为中文类别名，从而更好应用于中文情感分析系统中去！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 替换数据集中标签,{'sadness': '难过', 'happiness': '愉快', 'like': '喜欢', 'anger': '愤怒', 'fear': '害怕', 'surprise': '惊讶', 'disgust': '厌恶'}\r\n",
    "data.loc[data['label']=='sadness', 'label'] = '难过'\r\n",
    "data.loc[data['label']=='happiness', 'label'] = '愉快'\r\n",
    "data.loc[data['label']=='like', 'label'] = '喜欢'\r\n",
    "data.loc[data['label']=='anger', 'label'] = '愤怒'\r\n",
    "data.loc[data['label']=='fear', 'label'] = '害怕'\r\n",
    "data.loc[data['label']=='surprise', 'label'] = '惊讶'\r\n",
    "data.loc[data['label']=='disgust', 'label'] = '厌恶'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.4 手动划分训练、验证和测试集\n",
    "\n",
    "划分训练、验证和测试集原因：\n",
    "\n",
    "a)训练集直接参与了模型调参的过程，显然不能用来反映模型真实的能力（防止课本死记硬背的学生拥有最好的成绩，即防止过拟合)。\n",
    "\n",
    "b)验证集参与了人工调参(超参数)的过程，也不能用来最终评判一个模型（刷题库的学生不能算是学习好的学生）。\n",
    "\n",
    "c) 所以要通过最终的考试(测试集)来考察一个学(模)生(型)真正的能力（期末考试）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/6090879c930f4bee837d12d8e0e8dacb60cea682899e417db4cc7bb88348f0e8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**下面提供了两种较常见的数据集划分方式，可以根据具体需要或效果进行选择：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # # 划分方式1：根据比例直接划分训练、验证和测试集\r\n",
    "# from sklearn.model_selection import train_test_split\r\n",
    "# train_data, test_data = train_test_split(data, test_size=0.2)\r\n",
    "# train_data,valid_data=train_test_split(train_data, test_size=0.2)\r\n",
    "\r\n",
    "# # 对数据进行随机打乱\r\n",
    "# from sklearn.utils import shuffle\r\n",
    "# train_data = shuffle(train_data)\r\n",
    "# valid_data = shuffle(valid_data)\r\n",
    "# test_data = shuffle(test_data)\r\n",
    "\r\n",
    "# # 保存划分好的数据集文件\r\n",
    "# train_data.to_csv('./train.csv', index=False, sep=\"\\t\") # 训练集\r\n",
    "# valid_data.to_csv('./valid.csv', index=False, sep=\"\\t\")  # 验证集\r\n",
    "# test_data.to_csv('./test.csv', index=False, sep=\"\\t\")   # 测试集\r\n",
    "\r\n",
    "# print('训练集长度：', len(train_dat), '验证集长度：', len(valid_data), '测试集长度', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集长度： 28558 验证集长度： 3570 测试集长度 3566\n"
     ]
    }
   ],
   "source": [
    "# 划分方式2：根据具体类别按8：1：1去划分训练、验证和测试集,这样可以使得数据尽量同分布\r\n",
    "\r\n",
    "from sklearn.utils import shuffle\r\n",
    "train = pd.DataFrame()  # 训练集\r\n",
    "valid = pd.DataFrame()  # 验证集\r\n",
    "test = pd.DataFrame()  # 测试集\r\n",
    "\r\n",
    "tags = data['label'].unique().tolist()  # 按照该标签进行等比例抽取\r\n",
    "\r\n",
    "# 根据数据集的类别按8:1:1的比例划分训练、验证和测试集并随机打乱后保存\r\n",
    "for tag in tags:\r\n",
    "    # 随机选取0.2的数据作为训练和验证集\r\n",
    "    target = data[(data['label'] == tag)]\r\n",
    "    sample = target.sample(int(0.2 * len(target)))\r\n",
    "    sample_index = sample.index\r\n",
    "    # 将剩余0.8的数据作为训练集\r\n",
    "    all_index = target.index\r\n",
    "    residue_index = all_index.difference(sample_index)  # 去除sample之后剩余的数据\r\n",
    "    residue = target.loc[residue_index]\r\n",
    "    # 对划分出来的0.2的数据集按等比例进行测试集和验证集的划分\r\n",
    "    test_sample = sample.sample(int(0.5 * len(sample)))\r\n",
    "    test_sample_index = test_sample.index\r\n",
    "    valid_sample_index = sample_index.difference(test_sample_index)\r\n",
    "    valid_sample = sample.loc[valid_sample_index]\r\n",
    "    # 拼接各个类别\r\n",
    "    test = pd.concat([test, test_sample], ignore_index=True)\r\n",
    "    valid = pd.concat([valid, valid_sample], ignore_index=True)\r\n",
    "    train = pd.concat([train, residue], ignore_index=True)\r\n",
    "    # 对数据进行随机打乱\r\n",
    "    train = shuffle(train)\r\n",
    "    valid = shuffle(valid)\r\n",
    "    test = shuffle(test)\r\n",
    "\r\n",
    "# 保存为tab分隔的文本\r\n",
    "train.to_csv('train.csv', sep='\\t', index=False)  # 训练集\r\n",
    "valid.to_csv('valid.csv', sep='\\t', index=False)  # 验证集\r\n",
    "test.to_csv('test.csv', sep='\\t', index=False)    # 测试集\r\n",
    "\r\n",
    "print('训练集长度：', len(train), '验证集长度：', len(valid), '测试集长度', len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 四.  基于PaddleHub构建微情感分析模型\n",
    "\n",
    "**PaddleHub简介：**\n",
    "\n",
    "PaddleHub是飞桨预训练模型管理和迁移学习工具，通过PaddleHub开发者可以使用高质量的预训练模型结合Fine-tune API快速完成迁移学习到应用部署的全流程工作。其提供了飞桨生态下的高质量预训练模型，涵盖了图像分类、目标检测、词法分析、语义模型、情感分析、视频分类、图像生成、图像分割、文本审核、关键点检测等主流模型。\n",
    "\n",
    "更多模型详情请查看官网：https://www.paddlepaddle.org.cn/hub\n",
    "\n",
    "PaddleHub 使用过程中，遇到问题可以提issue： https://github.com/PaddlePaddle/PaddleHub/issues\n",
    "\n",
    "基于预训练模型，PaddleHub支持以下功能：\n",
    "\n",
    "1.模型即软件，通过Python API或命令行实现快速预测，更方便地使用PaddlePaddle模型库。\n",
    "\n",
    "2.迁移学习，用户通过Fine-tune API，只需要少量代码即可完成自然语言处理和计算机视觉场景的深度 迁移学习。\n",
    "\n",
    "3.服务化部署，简单一行命令即可搭建属于自己的模型的API服务。\n",
    "\n",
    "4.超参优化，自动搜索最优超参，得到更好的模型效果。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/2ec3cbb556b842479dfbbc051331b4064d737f2293754db2a42fdc7c1aaafc4b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/0ad5564287fb48b0b5754f741c25919b83fd8a30af2644e1a3979e9e77c336e0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4.1 前置环境准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 下载最新版本的paddlehub\r\n",
    "!pip install -U paddlehub -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 导入paddlehub和paddle包\r\n",
    "import paddlehub as hub\r\n",
    "import paddle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4.2 加载预训练模型-ERNIE Tiny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "ERNIE Tiny 主要通过模型结构压缩和模型蒸馏的方法，将 ERNIE 2.0 Base 模型进行压缩。特点和优势如下：\n",
    "\n",
    "a.采用 3 层 transformer 结构，线性提速 4 倍;\n",
    "\n",
    "b.模型加宽隐层参数，从 ERNIE 2.0 的 768 扩展到 1024；\n",
    "\n",
    "c.缩短输入文本的序列长度，降低计算复杂度，模型首次采用中文 subword 粒度输入，长度平均缩短 40%；\n",
    "\n",
    "d.ERNIE Tiny 在训练中扮演学生角色，利用模型蒸馏的方式在 Transformer 层和 Prediction 层学习教师模型 ERNIE 2.0 模型对应层的分布和输出;\n",
    "\n",
    "综合优化能带来4.3倍的预测提速，具有更高的工业落地能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/39e3b9125e124af290dee3c00dcc7f871de727a04f6142f1a380b98f45be2aa8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['难过', '愉快', '喜欢', '愤怒', '害怕', '惊讶', '厌恶']\n",
      "{0: '难过', 1: '愉快', 2: '喜欢', 3: '愤怒', 4: '害怕', 5: '惊讶', 6: '厌恶'}\n"
     ]
    }
   ],
   "source": [
    "# 设置要求进行分类的7个情感类别\r\n",
    "label_list=list(data.label.unique())\r\n",
    "print(label_list)\r\n",
    "\r\n",
    "label_map = { \r\n",
    "    idx: label_text for idx, label_text in enumerate(label_list)\r\n",
    "}\r\n",
    "print(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download https://bj.bcebos.com/paddlehub/paddlehub_dev/ernie_tiny_2.0.2.tar.gz\n",
      "[##################################################] 100.00%\n",
      "Decompress /home/aistudio/.paddlehub/tmp/tmpyvupawg3/ernie_tiny_2.0.2.tar.gz\n",
      "[##################################################] 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-08-04 23:21:25,328] [    INFO] - Successfully installed ernie_tiny-2.0.2\n",
      "[2021-08-04 23:21:25,332] [    INFO] - Downloading https://paddlenlp.bj.bcebos.com/models/transformers/ernie_tiny/ernie_tiny.pdparams and saved to /home/aistudio/.paddlenlp/models/ernie-tiny\n",
      "[2021-08-04 23:21:25,335] [    INFO] - Downloading ernie_tiny.pdparams from https://paddlenlp.bj.bcebos.com/models/transformers/ernie_tiny/ernie_tiny.pdparams\n",
      "100%|██████████| 354158/354158 [00:04<00:00, 71445.77it/s]\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1297: UserWarning: Skip loading for classifier.weight. classifier.weight is not found in the provided dict.\n",
      "  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1297: UserWarning: Skip loading for classifier.bias. classifier.bias is not found in the provided dict.\n",
      "  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\n"
     ]
    }
   ],
   "source": [
    "# 只需指定想要使用的模型名称和文本分类的类别数即可完成Fine-tune网络定义，在预训练模型后拼接上一个全连接网络（Full Connected）进行分类\r\n",
    "# 此处选择ernie_tiny预训练模型并设置微调任务为7分类任务\r\n",
    "model = hub.Module(name=\"ernie_tiny\", task='seq-cls', num_classes=7, label_map=label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "`hub.Module`的参数用法如下：\n",
    "\n",
    "* `name`：模型名称，可以选择`ernie`，`ernie_tiny`，`bert-base-cased`， `bert-base-chinese`, `roberta-wwm-ext`，`roberta-wwm-ext-large`等。\n",
    "* `task`：fine-tune任务。此处为`seq-cls`，表示文本分类任务。\n",
    "* `num_classes`：表示当前文本分类任务的类别数，根据具体使用的数据集确定，默认为2，需要根据具体分类任务进行选定。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "[PaddleHub模型搜索](https://www.paddlepaddle.org.cn/hublist)\n",
    "\n",
    "PaddleHub还提供BERT等模型可供选择, 当前支持文本分类任务的模型对应的加载示例如下：\n",
    "\n",
    "模型名                           | PaddleHub Module\n",
    "---------------------------------- | :------:\n",
    "ERNIE, Chinese                     | `hub.Module(name='ernie')`\n",
    "ERNIE tiny, Chinese                | `hub.Module(name='ernie_tiny')`\n",
    "ERNIE 2.0 Base, English            | `hub.Module(name='ernie_v2_eng_base')`\n",
    "ERNIE 2.0 Large, English           | `hub.Module(name='ernie_v2_eng_large')`\n",
    "BERT-Base, English Cased           | `hub.Module(name='bert-base-cased')`\n",
    "BERT-Base, English Uncased         | `hub.Module(name='bert-base-uncased')`\n",
    "BERT-Large, English Cased          | `hub.Module(name='bert-large-cased')`\n",
    "BERT-Large, English Uncased        | `hub.Module(name='bert-large-uncased')`\n",
    "BERT-Base, Multilingual Cased      | `hub.Module(nane='bert-base-multilingual-cased')`\n",
    "BERT-Base, Multilingual Uncased    | `hub.Module(nane='bert-base-multilingual-uncased')`\n",
    "BERT-Base, Chinese                 | `hub.Module(name='bert-base-chinese')`\n",
    "BERT-wwm, Chinese                  | `hub.Module(name='chinese-bert-wwm')`\n",
    "BERT-wwm-ext, Chinese              | `hub.Module(name='chinese-bert-wwm-ext')`\n",
    "RoBERTa-wwm-ext, Chinese           | `hub.Module(name='roberta-wwm-ext')`\n",
    "RoBERTa-wwm-ext-large, Chinese     | `hub.Module(name='roberta-wwm-ext-large')`\n",
    "RBT3, Chinese                      | `hub.Module(name='rbt3')`\n",
    "RBTL3, Chinese                     | `hub.Module(name='rbtl3')`\n",
    "ELECTRA-Small, English             | `hub.Module(name='electra-small')`\n",
    "ELECTRA-Base, English              | `hub.Module(name='electra-base')`\n",
    "ELECTRA-Large, English             | `hub.Module(name='electra-large')`\n",
    "ELECTRA-Base, Chinese              | `hub.Module(name='chinese-electra-base')`\n",
    "ELECTRA-Small, Chinese             | `hub.Module(name='chinese-electra-small')`\n",
    "\n",
    "通过以上的一行代码，`model`初始化为一个适用于文本分类任务的模型，为ERNIE的预训练模型后拼接上一个全连接网络（Full Connected）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4.3 加载并处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 导入依赖库\r\n",
    "import os, io, csv\r\n",
    "from paddlehub.datasets.base_nlp_dataset import InputExample, TextClassificationDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 数据集存放位置\r\n",
    "DATA_DIR=\"/home/aistudio/data/data100731/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-08-04 23:21:44,835] [    INFO] - Downloading vocab.txt from https://paddlenlp.bj.bcebos.com/models/transformers/ernie_tiny/vocab.txt\n",
      "100%|██████████| 459/459 [00:00<00:00, 5903.16it/s]\n",
      "[2021-08-04 23:21:45,047] [    INFO] - Downloading spm_cased_simp_sampled.model from https://paddlenlp.bj.bcebos.com/models/transformers/ernie_tiny/spm_cased_simp_sampled.model\n",
      "100%|██████████| 1083/1083 [00:00<00:00, 11921.14it/s]\n",
      "[2021-08-04 23:21:45,199] [    INFO] - Downloading dict.wordseg.pickle from https://paddlenlp.bj.bcebos.com/models/transformers/ernie_tiny/dict.wordseg.pickle\n",
      "100%|██████████| 161822/161822 [00:02<00:00, 65316.99it/s]\n",
      "[2021-08-04 23:22:00,079] [    INFO] - Found /home/aistudio/.paddlenlp/models/ernie-tiny/vocab.txt\n",
      "[2021-08-04 23:22:00,083] [    INFO] - Found /home/aistudio/.paddlenlp/models/ernie-tiny/spm_cased_simp_sampled.model\n",
      "[2021-08-04 23:22:00,087] [    INFO] - Found /home/aistudio/.paddlenlp/models/ernie-tiny/dict.wordseg.pickle\n",
      "[2021-08-04 23:22:05,911] [    INFO] - Found /home/aistudio/.paddlenlp/models/ernie-tiny/vocab.txt\n",
      "[2021-08-04 23:22:05,914] [    INFO] - Found /home/aistudio/.paddlenlp/models/ernie-tiny/spm_cased_simp_sampled.model\n",
      "[2021-08-04 23:22:05,916] [    INFO] - Found /home/aistudio/.paddlenlp/models/ernie-tiny/dict.wordseg.pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text=是不是世界上有一种人不甘心屈居人下,是不是有一种人争一辈子竟不得,是不是有一种人宁肯死亡也不苟活。是不是有一种人被迫不能放弃。大半年了,我累了,槿汐,可是还没到安心睡觉的时候。\tlabel=喜欢\n",
      "text=我喜欢大关县的花开花谢,都无比美丽\tlabel=喜欢\n",
      "text=没有找到。\tlabel=难过\n",
      "text=徐洁奇和狗日的文学课ppt\tlabel=愤怒\n",
      "text=-我要午睡,安。\tlabel=厌恶\n",
      "text=开会,我没准备的情况下上去做presentation,某人替我捏着一大把汗。还好平时工作清楚,干脆利落三分钟把两个项目讲清楚,进展,问题,行动计划,时间死线一一讲明,满屋中外友人频频点头,某人和某人盯着我笑,齐齐偷偷冲我竖大拇指。呵呵,用英语讲工作是俺强项。哎呀,真爽。\tlabel=愉快\n",
      "text=还是需要给自己开个处方1熬,结合众人的经验这是必须的过程。2需要不断的肯定的心理暗示3需要从平时做的英语练习中工作中获得满足感和被肯定的感觉4这个是我上铺说的,必须有一件事情能给我强大的正面刺激5不间断的运动,以释放心理能量\tlabel=难过\n",
      "text=呜呜呜.贴吧密码忘了.登不了了.\tlabel=难过\n",
      "text=嘻嘻已经拒绝睡前讲唐诗有两个多月了吧,今天拿出唐诗准备讲讲,结果她自己叽咕叽咕的都背出来了,我说首诗名,她背诗,就这样一口气背了五六十首,真是让我惊喜不已!\tlabel=愉快\n"
     ]
    }
   ],
   "source": [
    "# 对数据进行处理，处理为模型可接受的格式\r\n",
    "class OCEMOTION(TextClassificationDataset):\r\n",
    "    def __init__(self, tokenizer, mode='train', max_seq_len=128):\r\n",
    "        if mode == 'train':\r\n",
    "            data_file = 'train.csv'  # 训练集\r\n",
    "        elif mode == 'test':\r\n",
    "            data_file = 'test.csv'   # 测试集\r\n",
    "        else:\r\n",
    "            data_file = 'valid.csv'  # 验证集\r\n",
    "        \r\n",
    "        super(OCEMOTION, self).__init__(\r\n",
    "            base_path=DATA_DIR,\r\n",
    "            data_file=data_file,\r\n",
    "            tokenizer=tokenizer,\r\n",
    "            max_seq_len=max_seq_len,\r\n",
    "            mode=mode,\r\n",
    "            is_file_with_header=True,\r\n",
    "            label_list=label_list\r\n",
    "            )\r\n",
    "\r\n",
    "    # 解析文本文件里的样本\r\n",
    "    def _read_file(self, input_file, is_file_with_header: bool = False):\r\n",
    "        if not os.path.exists(input_file):\r\n",
    "            raise RuntimeError(\"The file {} is not found.\".format(input_file))\r\n",
    "        else:\r\n",
    "            with io.open(input_file, \"r\", encoding=\"UTF-8\") as f:\r\n",
    "                reader = csv.reader(f, delimiter=\"\\t\")\r\n",
    "                examples = []\r\n",
    "                seq_id = 0\r\n",
    "                header = next(reader) if is_file_with_header else None\r\n",
    "                for line in reader:\r\n",
    "                    try:\r\n",
    "                        example = InputExample(guid=seq_id, text_a=line[0], label=line[1])\r\n",
    "                        seq_id += 1\r\n",
    "                        examples.append(example)\r\n",
    "                    except:\r\n",
    "                        continue\r\n",
    "                return examples\r\n",
    "                \r\n",
    "train_dataset = OCEMOTION(model.get_tokenizer(), mode='train', max_seq_len=128)  # max_seq_len根据具体文本长度进行确定，但需注意max_seq_len最长不超过512\r\n",
    "dev_dataset = OCEMOTION(model.get_tokenizer(), mode='dev', max_seq_len=128)\r\n",
    "test_dataset = OCEMOTION(model.get_tokenizer(), mode='test', max_seq_len=128)\r\n",
    "\r\n",
    "# 查看训练集前3条\r\n",
    "for e in train_dataset.examples[:3]:\r\n",
    "    print(e)\r\n",
    "# 查看验证集前3条\r\n",
    "for e in dev_dataset.examples[:3]:\r\n",
    "    print(e)\r\n",
    "# 查看测试集前3条\r\n",
    "for e in test_dataset.examples[:3]:\r\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4.4 选择优化策略和运行配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 优化器的选择，此处使用了AdamW优化器\r\n",
    "optimizer = paddle.optimizer.AdamW(learning_rate=4e-5, parameters=model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-08-04 23:22:30,859] [ WARNING] - PaddleHub model checkpoint not found, start from scratch...\n"
     ]
    }
   ],
   "source": [
    "# 运行配置\r\n",
    "trainer = hub.Trainer(model, optimizer, checkpoint_dir='./ckpt', use_gpu=True, use_vdl=True)      # fine-tune任务的执行者"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 运行配置\n",
    "\n",
    "`Trainer` 主要控制Fine-tune任务的训练，是任务的发起者，包含以下可控制的参数:\n",
    "\n",
    "* `model`: 被优化模型；\n",
    "* `optimizer`: 优化器选择；\n",
    "* `use_gpu`: 是否使用gpu训练；\n",
    "* `use_vdl`: 是否使用vdl可视化训练过程；\n",
    "* `checkpoint_dir`: 保存模型参数的地址；\n",
    "* `compare_metrics`: 保存最优模型的衡量指标；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4.5 模型训练和验证\n",
    "\n",
    "注意模型的训练需要GPU环境，在模型训练时可以通过下方的'性能监控'或者在终端输入'nvdia-smi'命令查看显存占用情况，若显存不足可以适当调小batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer.train(train_dataset, epochs=5, batch_size=256, eval_dataset=dev_dataset, save_interval=1)   # 配置训练参数，启动训练，并指定验证集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "`trainer.train` 主要控制具体的训练过程，包含以下可控制的参数：\n",
    "\n",
    "* `train_dataset`: 训练时所用的数据集；\n",
    "* `epochs`: 训练轮数；\n",
    "* `batch_size`: 训练的批大小，如果使用GPU，请根据实际情况调整batch_size；\n",
    "* `num_workers`: works的数量，默认为0；\n",
    "* `eval_dataset`: 验证集；\n",
    "* `log_interval`: 打印日志的间隔， 单位为执行批训练的次数。\n",
    "* `save_interval`: 保存模型的间隔频次，单位为执行训练的轮数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4.6 在测试集上评估当前训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-08-04 23:30:35,095] [    INFO] - Evaluation on validation dataset: \\\n",
      "[2021-08-04 23:30:38,511] [    EVAL] - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - Evaluation on validation dataset: / - Evaluation on validation dataset: - - Evaluation on validation dataset: \\ - Evaluation on validation dataset: | - [Evaluation result] avg_acc=0.5939\n"
     ]
    }
   ],
   "source": [
    "# 在测试集上评估当前训练模型\r\n",
    "result = trainer.evaluate(test_dataset, batch_size=128) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-08-04 23:30:38,536] [    INFO] - Found /home/aistudio/.paddlenlp/models/ernie-tiny/vocab.txt\n",
      "[2021-08-04 23:30:38,539] [    INFO] - Found /home/aistudio/.paddlenlp/models/ernie-tiny/spm_cased_simp_sampled.model\n",
      "[2021-08-04 23:30:38,542] [    INFO] - Found /home/aistudio/.paddlenlp/models/ernie-tiny/dict.wordseg.pickle\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/creation.py:125: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if data.dtype == np.object:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48899184212664987 0.5591275726811291 0.4574688432467382\n"
     ]
    }
   ],
   "source": [
    "# 进阶扩展： 使用F1-score指标对测试集上效果进行更官方的评测\r\n",
    "import numpy as np\r\n",
    "# 读取测试集文件\r\n",
    "df = pd.read_csv('./test.csv',sep = '\\t')\r\n",
    "\r\n",
    "news1 = pd.DataFrame(columns=['label'])\r\n",
    "news1['label'] = df[\"label\"]\r\n",
    "news = pd.DataFrame(columns=['text_a'])\r\n",
    "news['text_a'] = df[\"text_a\"]\r\n",
    "\r\n",
    "# 首先将pandas读取的数据转化为array\r\n",
    "data_array = np.array(news)\r\n",
    "# 然后转化为list形式\r\n",
    "data_list =data_array.tolist()\r\n",
    "\r\n",
    "# 对测试集进行预测得到预测的类别标签\r\n",
    "y_pre = model.predict(data_list, max_seq_len=128, batch_size=128, use_gpu=True)\r\n",
    "\r\n",
    "# 测试集的真实类别标签\r\n",
    "data_array1 = np.array(news1)\r\n",
    "y_val =data_array1.tolist()\r\n",
    "\r\n",
    "# 计算预测结果的F1-score\r\n",
    "from sklearn.metrics import precision_recall_fscore_support,f1_score,precision_score,recall_score\r\n",
    "f1 = f1_score(y_val, y_pre, average='macro')\r\n",
    "p = precision_score(y_val, y_pre, average='macro')\r\n",
    "r = recall_score(y_val, y_pre, average='macro')\r\n",
    "print(f1, p, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "> ps:感兴趣的可以在基线模型的基础上通过调参、选用其他预训练模型、优化网络结构、重新预训练等方式进一步优化效果哦！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4.7 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-08-04 23:30:48,174] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-tiny/ernie_tiny.pdparams\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1297: UserWarning: Skip loading for classifier.weight. classifier.weight is not found in the provided dict.\n",
      "  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py:1297: UserWarning: Skip loading for classifier.bias. classifier.bias is not found in the provided dict.\n",
      "  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\n",
      "[2021-08-04 23:30:54,070] [    INFO] - Loaded parameters from /home/aistudio/data/data100731/ckpt/best_model/model.pdparams\n",
      "[2021-08-04 23:30:54,077] [    INFO] - Found /home/aistudio/.paddlenlp/models/ernie-tiny/vocab.txt\n",
      "[2021-08-04 23:30:54,080] [    INFO] - Found /home/aistudio/.paddlenlp/models/ernie-tiny/spm_cased_simp_sampled.model\n",
      "[2021-08-04 23:30:54,083] [    INFO] - Found /home/aistudio/.paddlenlp/models/ernie-tiny/dict.wordseg.pickle\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/creation.py:125: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if data.dtype == np.object:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: 你也不用说对不起,只是若相惜 \t Lable: 难过\n",
      "Data: 幸福其实很简单 \t Lable: 愉快\n",
      "Data: 恐惧感啊。生病 \t Lable: 害怕\n",
      "Data: 待你长发及腰,我们一起耕耘时光。我愿等待 \t Lable: 喜欢\n"
     ]
    }
   ],
   "source": [
    "# 要进行预测的数据\r\n",
    "data = [\r\n",
    "    # 难过\r\n",
    "    [\"你也不用说对不起,只是若相惜\"],\r\n",
    "    # 愉快\r\n",
    "    [\"幸福其实很简单\"],\r\n",
    "    # 害怕\r\n",
    "    [\"恐惧感啊。生病\"],\r\n",
    "    # 喜欢\r\n",
    "    [\"待你长发及腰,我们一起耕耘时光。我愿等待\"]\r\n",
    "]\r\n",
    "\r\n",
    "# 定义要进行情感分类的7个类别\r\n",
    "label_list=['难过', '愉快', '喜欢', '愤怒', '害怕', '惊讶', '厌恶']\r\n",
    "label_map = {\r\n",
    "    idx: label_text for idx, label_text in enumerate(label_list)\r\n",
    "}\r\n",
    "\r\n",
    "# 加载训练好的模型\r\n",
    "model = hub.Module(\r\n",
    "    name='ernie_tiny',\r\n",
    "    task='seq-cls',\r\n",
    "    num_classes=7,\r\n",
    "    load_checkpoint='./ckpt/best_model/model.pdparams',\r\n",
    "    label_map=label_map)\r\n",
    "\r\n",
    "# 进行模型预测\r\n",
    "results = model.predict(data, max_seq_len=128, batch_size=1, use_gpu=True)\r\n",
    "for idx, text in enumerate(data):\r\n",
    "    print('Data: {} \\t Lable: {}'.format(text[0], results[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 五. 基于PyQt5完成可视化界面演示\n",
    "ps:基于PyQt5的可视化界面核心代码已放至work/中文微情感分析系统下，将整个文件夹下载到本地后，根据提供的环境配置指南及使用说明进行操作即可运行！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 将刚才训练好的最优模型参赛移动到work目录下，从而更好保存！\r\n",
    "!cp -r /home/aistudio/data/data100731/ckpt/best_model/model.pdparams /home/aistudio/work/中文微情感分析系统/best_model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "5.1 PyQt5介绍：\n",
    "\n",
    "   PyQt5 是基于 Digia 公司强大的图形程式框架 Qt5 的 python 接口，其构建的程序可以运行于多个平台，包括：Unix、Windows 和Mac OS。QT给我们带来最方便的好处，就是它有一个QT Desiginer，这个设计器可以方便我们进行页面的布局，可以说在Tkinter里面需要一坨坨的代码完成的页面布局，在QT里面只要拖一拖控件就搞定了。\n",
    "\n",
    "5.2 前置准备-PyQt5+Pycharm的安装和配置： \n",
    "\n",
    "  [PyQt5+Pycharm安装和配置图文教程详解](https://www.jb51.net/article/183411.htm) 网上教程较多，根据网上教程进行操作即可。\n",
    "\n",
    "5.3 使用教程： \n",
    "\n",
    "   在完成PyQt5的安装和配置后，使用 Qt 提供的 Qt designer 软件通过拖拽即可完成页面设计UI文件然后将其导出为.py文件即页面设计程序。接着通过对界面button按钮及输入框等元素绑定相应功能函数即可完成整个系统界面功能的添加。（网上教程较多，这里不多赘述，直接上手体验更佳！）\n",
    "\n",
    "5.4 界面美化： \n",
    "\n",
    "  [Python图形界面美化的方法论](https://zmister.com/archives/1589.html)，学会充分利用QSS及添加图片等美化界面效果。\n",
    "\n",
    "本项目界面相关代码请查看‘中文微情感分析系统’文件夹下的interface.py（界面设计程序）和gui.py（主程序）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**可视化界面演示：**\n",
    "\n",
    "1. 单条文本情感分析页面：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/5bd476711b7e4bc5bf43185d917efa7deb571f11d6e54c1d8c76d3d09cc35210)\n",
    "\n",
    "2. 批量文本情感分析页面：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/08a11931b4834349aa3eef1e356a20314de1ebc25faf4edf9a204d31a6fe1fec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 六. 系统打包\n",
    "6.1 应用场景：\n",
    "\n",
    "在完成系统的开发后，我们可以通过PyInstaller等完成整个python程序的打包，从而可在各平台上直接使用，免去复杂环境配置操作，更好交付给一些小白或未安装Python的小伙伴们使用也便于演示。\n",
    "\n",
    "6.2 打包教程：\n",
    "\n",
    "**Pyinstaller**打包网上教程较多，这里也不多赘述了，善用搜索引擎即可。[【解决方案】Pyinstaller打包exe文件详细教程](https://blog.csdn.net/chichu261/article/details/106392385)\n",
    "\n",
    "除了比较常用的Pyinstaller，Windows用户也可以尝试下使用GT大佬的**QPT**进行系统程序的打包，体验更佳哦！使用上直接根据其提供的教程进行操作即可。\n",
    "\n",
    "[QPT - Quick packaging tool 快捷封装工具](https://github.com/QPT-Family/QPT)，QPT是一款可以“模拟”开发环境的多功能封装工具，最短只需一行命令即可将普通的Python脚本打包成EXE可执行程序，并选择性添加CUDA和NoAVX的支持，尽可能兼容更多用户环境。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 七. 项目总结\n",
    "\n",
    "该项目为本人目前在做的‘舆情分析系统’的一个衍生子项目‘微情感分析系统’，开源该项目教程更多希望能够帮助大家更好地上手一个完整的文本分类项目开发流程，全流程式的实战开发教程项目在AI Studio上目前感觉还是比较匮乏的，希望本项目能够对大家有所启发或帮助，从而更好拿下竞赛或毕设等项目！\n",
    "\n",
    "到这儿，本项目就告一段落了。若大家喜欢，希望能够fork喜欢关注三连！❤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 八. 个人介绍\n",
    "> 华南师范大学 软件学院 软件工程专业 2019级 本科生 黄灿桦\n",
    "\n",
    "> 主要方向：搞开发，目前主攻NLP和数据挖掘相关比赛或项目\n",
    "\n",
    "> Github地址：https://github.com/hchhtc123\n",
    "\n",
    "> 昵称：[炼丹师233](https://aistudio.baidu.com/aistudio/personalcenter/thirdview/330406)\n",
    "\n",
    "> [https://aistudio.baidu.com/aistudio/personalcenter/thirdview/330406](https://aistudio.baidu.com/aistudio/personalcenter/thirdview/330406)   关注我，下次带来更多精彩项目分享！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/de2c74517629464a9731aa706fd8ab7b20badb8aecdb4afe8b107e6158d3b035)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
